{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem()\n",
    "dir = 'sagemaker-simclr-dataset/datasets/0005f7aaab2800f6170c399693a96917'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_file_allowed_extension(filename, extensions):\n",
    "    \"\"\"Checks if a file is an allowed extension.\n",
    "\n",
    "    Args:\n",
    "        filename (string): path to a file\n",
    "        extensions (tuple of strings): extensions to consider (lowercase)\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the filename ends with one of given extensions\n",
    "    \"\"\"\n",
    "    return filename.lower().endswith(extensions)\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    \"\"\"Checks if a file is an allowed image extension.\n",
    "\n",
    "    Args:\n",
    "        filename (string): path to a file\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the filename ends with a known image extension\n",
    "    \"\"\"\n",
    "    return has_file_allowed_extension(filename, IMG_EXTENSIONS)\n",
    "\n",
    "def make_dataset(directory, class_to_idx, extensions=None, is_valid_file=None):\n",
    "    instances = []\n",
    "    directory = directory\n",
    "    both_none = extensions is None and is_valid_file is None\n",
    "    both_something = extensions is not None and is_valid_file is not None\n",
    "    if both_none or both_something:\n",
    "        raise ValueError(\"Both extensions and is_valid_file cannot be None or not None at the same time\")\n",
    "    if extensions is not None:\n",
    "        def is_valid_file(x):\n",
    "            return has_file_allowed_extension(x, extensions)\n",
    "    for target_class in sorted(class_to_idx.keys()):\n",
    "        class_index = class_to_idx[target_class]\n",
    "        target_dir = target_class\n",
    "        #if not os.path.isdir(target_dir):\n",
    "        #    continue\n",
    "        for fname in fs.ls(target_dir):\n",
    "            path = fname\n",
    "            if is_valid_file(path):\n",
    "                item = path, class_index\n",
    "                instances.append(item)\n",
    "    return instances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.vision import VisionDataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "class DatasetFolder(VisionDataset):\n",
    "    \"\"\"A generic data loader where the samples are arranged in this way: ::\n",
    "\n",
    "        root/class_x/xxx.ext\n",
    "        root/class_x/xxy.ext\n",
    "        root/class_x/xxz.ext\n",
    "\n",
    "        root/class_y/123.ext\n",
    "        root/class_y/nsdf3.ext\n",
    "        root/class_y/asd932_.ext\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory path.\n",
    "        loader (callable): A function to load a sample given its path.\n",
    "        extensions (tuple[string]): A list of allowed extensions.\n",
    "            both extensions and is_valid_file should not be passed.\n",
    "        transform (callable, optional): A function/transform that takes in\n",
    "            a sample and returns a transformed version.\n",
    "            E.g, ``transforms.RandomCrop`` for images.\n",
    "        target_transform (callable, optional): A function/transform that takes\n",
    "            in the target and transforms it.\n",
    "        is_valid_file (callable, optional): A function that takes path of a file\n",
    "            and check if the file is a valid file (used to check of corrupt files)\n",
    "            both extensions and is_valid_file should not be passed.\n",
    "\n",
    "     Attributes:\n",
    "        classes (list): List of the class names sorted alphabetically.\n",
    "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
    "        samples (list): List of (sample path, class_index) tuples\n",
    "        targets (list): The class_index value for each image in the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, loader, extensions=None, transform=None,\n",
    "                 target_transform=None, is_valid_file=None):\n",
    "        super(DatasetFolder, self).__init__(root, transform=transform,\n",
    "                                            target_transform=target_transform)\n",
    "        classes, class_to_idx = self._find_classes(self.root)\n",
    "        samples = make_dataset(self.root, class_to_idx, extensions, is_valid_file)\n",
    "        if len(samples) == 0:\n",
    "            msg = \"Found 0 files in subfolders of: {}\\n\".format(self.root)\n",
    "            if extensions is not None:\n",
    "                msg += \"Supported extensions are: {}\".format(\",\".join(extensions))\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "        self.loader = loader\n",
    "        self.extensions = extensions\n",
    "\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.samples = samples\n",
    "        self.targets = [s[1] for s in samples]\n",
    "\n",
    "    def _find_classes(self, dir):\n",
    "        \"\"\"\n",
    "        Finds the class folders in a dataset.\n",
    "\n",
    "        Args:\n",
    "            dir (string): Root directory path.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n",
    "\n",
    "        Ensures:\n",
    "            No class is a subdirectory of another.\n",
    "        \"\"\"\n",
    "        classes = [d for d in fs.ls(dir)]\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (sample, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "\n",
    "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with fs.open(path) as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "\n",
    "def accimage_loader(path):\n",
    "#    import accimage\n",
    "#    try:\n",
    "#        return accimage.Image(path)\n",
    "#    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "def default_loader(path):\n",
    "#    from torchvision import get_image_backend\n",
    "#    if get_image_backend() == 'accimage':\n",
    "#        return accimage_loader(path)\n",
    "#    else:\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "class pandaImageFolder(DatasetFolder):\n",
    "    \"\"\"A generic data loader where the images are arranged in this way: ::\n",
    "\n",
    "        root/dog/xxx.png\n",
    "        root/dog/xxy.png\n",
    "        root/dog/xxz.png\n",
    "\n",
    "        root/cat/123.png\n",
    "        root/cat/nsdf3.png\n",
    "        root/cat/asd932_.png\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory path.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "        is_valid_file (callable, optional): A function that takes path of an Image file\n",
    "            and check if the file is a valid file (used to check of corrupt files)\n",
    "\n",
    "     Attributes:\n",
    "        classes (list): List of the class names sorted alphabetically.\n",
    "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
    "        imgs (list): List of (image path, class_index) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None, target_transform=None,\n",
    "                 loader=default_loader, is_valid_file=None):\n",
    "        super(pandaImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "                                          transform=transform,\n",
    "                                          target_transform=target_transform,\n",
    "                                          is_valid_file=is_valid_file)\n",
    "        self.imgs = self.samples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.resnet_simclr import ResNetSimCLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "from loss.nt_xent import NTXentLoss\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from simclr import SimCLR\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from gaussian_blur import GaussianBlur\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLRDataTransform(object):\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        xi = self.transform(sample)\n",
    "        xj = self.transform(sample)\n",
    "        return xi, xj\n",
    "\n",
    "class DataSetWrapper(object):\n",
    "\n",
    "    def __init__(self, batch_size, num_workers, valid_size, input_shape, s):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.valid_size = valid_size\n",
    "        self.s = s\n",
    "        self.input_shape = eval(input_shape)\n",
    "\n",
    "    def get_data_loaders(self):\n",
    "        data_augment = self._get_simclr_pipeline_transform()\n",
    "        train_dataset = pandaImageFolder(root='sagemaker-simclr-dataset/datasets',\n",
    "                                       transform=SimCLRDataTransform(data_augment))\n",
    "        #train_dataset = PandasDataset(root_dir='/content/drive/My Drive/pandaspandas/a51ad4ec379a9209c740025a6d410708',\n",
    "        #                              transform=SimCLRDataTransform(data_augment)) #the only change need to make\n",
    "\n",
    "        train_loader, valid_loader = self.get_train_validation_data_loaders(train_dataset)\n",
    "        return train_loader, valid_loader\n",
    "\n",
    "    def _get_simclr_pipeline_transform(self):\n",
    "        # get a set of data augmentation transformations as described in the SimCLR paper.\n",
    "        color_jitter = transforms.ColorJitter(0.8 * self.s, 0.8 * self.s, 0.8 * self.s, 0.2 * self.s)\n",
    "        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=self.input_shape[0]),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                              transforms.RandomGrayscale(p=0.2),\n",
    "                                              transforms.ToTensor()])\n",
    "        return data_transforms\n",
    "\n",
    "    def get_train_validation_data_loaders(self, train_dataset):\n",
    "        # obtain training indices that will be used for validation\n",
    "        num_train = len(train_dataset)\n",
    "        indices = list(range(num_train))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        split = int(np.floor(self.valid_size * num_train))\n",
    "        train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "        # define samplers for obtaining training and validation batches\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, sampler=train_sampler,\n",
    "                                  num_workers=self.num_workers, drop_last=True, shuffle=False)\n",
    "\n",
    "        valid_loader = DataLoader(train_dataset, batch_size=self.batch_size, sampler=valid_sampler,\n",
    "                                  num_workers=self.num_workers, drop_last=True)\n",
    "        return train_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "dataset = DataSetWrapper(config['batch_size'], **config['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "Feature extractor: resnet18\n",
      "Pre-trained weights not found. Training from scratch.\n",
      "torch.Size([200, 3, 512, 512]) torch.Size([200, 3, 512, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 600.00 MiB (GPU 0; 11.17 GiB total capacity; 10.64 GiB already allocated; 204.31 MiB free; 10.65 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-201210dacd3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msimclr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimclr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/simclr.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mxjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 600.00 MiB (GPU 0; 11.17 GiB total capacity; 10.64 GiB already allocated; 204.31 MiB free; 10.65 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "simclr = SimCLR(dataset, config)\n",
    "simclr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
