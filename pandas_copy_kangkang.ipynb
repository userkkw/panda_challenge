{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5fa84165376b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets,models\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from scipy import spatial\n",
    "from sklearn.neighbors import BallTree\n",
    "from scipy.stats import mode\n",
    "import torch.nn.functional as F\n",
    "import os, time\n",
    "import sys\n",
    "sys.path.append(\"/storage/groups/qscd01/projects/HistologyColourNorm/MDMMsrc\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:VERSION 0.9.87.dev3\n"
     ]
    }
   ],
   "source": [
    "from pytorch_metric_learning import losses, miners, samplers, trainers, testers\n",
    "from pytorch_metric_learning.utils import common_functions\n",
    "import pytorch_metric_learning.utils.logging_presets as logging_presets\n",
    "from pytorch_metric_learning.utils.inference import MatchFinder, InferenceModel\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from cycler import cycler\n",
    "import record_keeper\n",
    "import pytorch_metric_learning\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info(\"VERSION %s\"%pytorch_metric_learning.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "We'll go through learning feature embeddings using different loss functions on TCGA-Colon dataset for classification and Hashing\n",
    "\n",
    "For every experiment the same embedding network is used and we don't do any hyperparameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # layer_sizes[0] is the dimension of the input\n",
    "    # layer_sizes[-1] is the dimension of the output\n",
    "    def __init__(self, layer_sizes, final_relu=False):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        layer_sizes = [int(x) for x in layer_sizes]\n",
    "        num_layers = len(layer_sizes) - 1\n",
    "        final_relu_layer = num_layers if final_relu else num_layers - 1\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            input_size = layer_sizes[i]\n",
    "            curr_size = layer_sizes[i + 1]\n",
    "            if i < final_relu_layer:\n",
    "                layer_list.append(nn.ReLU(inplace=True))\n",
    "            layer_list.append(nn.Linear(input_size, curr_size))\n",
    "        self.net = nn.Sequential(*layer_list)\n",
    "        self.last_linear = self.net[-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models, optimizers and image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set trunk model and replace the softmax layer with an identity function\n",
    "trunk = torchvision.models.resnet18(pretrained=True)\n",
    "trunk_output_size = trunk.fc.in_features\n",
    "trunk.fc = common_functions.Identity()\n",
    "trunk = torch.nn.DataParallel(trunk.to(device))\n",
    "\n",
    "# Set embedder model. This takes in the output of the trunk and outputs 64 dimensional embeddings\n",
    "embedder = torch.nn.DataParallel(MLP([trunk_output_size, 64]).to(device))\n",
    "\n",
    "# Set the classifier. The classifier will take the embeddings and output a 50 dimensional vector.\n",
    "# (Our training set will consist of the 9 classes)\n",
    "# We'll specify the classification loss further down in the code.\n",
    "classifier = torch.nn.DataParallel(MLP([64, 9])).to(device)\n",
    "\n",
    "# Set optimizers\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.00001, weight_decay=0.0001)\n",
    "embedder_optimizer = torch.optim.Adam(embedder.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Set the image transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "#         transforms.RandomRotation(30),\n",
    "#         transforms.CenterCrop(28),        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])}\n",
    "\n",
    "def print_decision(is_match):\n",
    "    if is_match:\n",
    "        print(\"Same class\")\n",
    "    else:\n",
    "        print(\"Different class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "         Identity-68                  [-1, 512]               0\n",
      "           ResNet-69                  [-1, 512]               0\n",
      "================================================================\n",
      "Total params: 11,176,512\n",
      "Trainable params: 11,176,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 106.00\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]          32,832\n",
      "            Linear-2                [-1, 1, 64]          32,832\n",
      "               MLP-3                [-1, 1, 64]               0\n",
      "================================================================\n",
      "Total params: 65,664\n",
      "Trainable params: 65,664\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 0.25\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1, 9]             585\n",
      "            Linear-2                 [-1, 1, 9]             585\n",
      "               MLP-3                 [-1, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 1,170\n",
      "Trainable params: 1,170\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(trunk,(3, 224,224))\n",
    "summary(embedder,(1,512))\n",
    "summary(classifier,(1,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the dataset and class-disjoint train/val splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args :\n",
    "    a2b=1\n",
    "    concat= 1\n",
    "    crop_size= 512\n",
    "    dis_norm= None\n",
    "    dis_scale= 3\n",
    "    dis_spectral_norm= False\n",
    "    display_dir= 'logs'\n",
    "    display_freq= 1\n",
    "    dataroot='/storage/groups/qscd01/projects/HistologyColourNorm/DRIT-master/datasets/Hist1/'\n",
    "    gpu= 0\n",
    "    input_dim =3\n",
    "    isDcontent=False\n",
    "    nThreads= 4\n",
    "    name='Histology2'\n",
    "    num= 2\n",
    "    num_domains= 5\n",
    "    phase= 'test'\n",
    "    resize_size= 1000\n",
    "    result_dir= '/storage/groups/qscd01/projects/HistologyColourNorm/outputs'\n",
    "    resume='/storage/groups/qscd01/projects/HistologyColourNorm/MDMMsrc/results/Histology/00004.pth'\n",
    "opts = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- load model ---\n",
      "<generator object Module.parameters at 0x7fb87df79350>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MD_multi(\n",
       "  (dis1): MD_Dis(\n",
       "    (model): Sequential(\n",
       "      (0): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv1): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(1024, 5, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       "  (dis2): MD_Dis(\n",
       "    (model): Sequential(\n",
       "      (0): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv1): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(1024, 5, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       "  (enc_c): MD_E_content(\n",
       "    (conv): Sequential(\n",
       "      (0): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "          (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ReLUINSConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ReLUINSConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): INSResBlock(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (4): INSResBlock(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (5): INSResBlock(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (6): INSResBlock(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GaussianNoiseLayer()\n",
       "    )\n",
       "  )\n",
       "  (enc_a): MD_E_attr_concat(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=8, bias=True)\n",
       "    )\n",
       "    (fcVar): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=8, bias=True)\n",
       "    )\n",
       "    (conv): Sequential(\n",
       "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (1): Conv2d(8, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (2): BasicBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): LeakyReLU(negative_slope=0.2)\n",
       "          (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2)\n",
       "          (4): Sequential(\n",
       "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): LeakyReLU(negative_slope=0.2)\n",
       "          (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2)\n",
       "          (4): Sequential(\n",
       "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (1): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv): Sequential(\n",
       "          (0): LeakyReLU(negative_slope=0.2)\n",
       "          (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.2)\n",
       "          (4): Sequential(\n",
       "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): LeakyReLU(negative_slope=0.2)\n",
       "      (6): AdaptiveAvgPool2d(output_size=1)\n",
       "    )\n",
       "  )\n",
       "  (gen): MD_G_multi_concat(\n",
       "    (dec_share): Sequential(\n",
       "      (0): INSResBlock(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec1): Sequential(\n",
       "      (0): INSResBlock(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(269, 269, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(269, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(269, 269, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(269, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): INSResBlock(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(269, 269, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(269, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(269, 269, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(269, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (2): INSResBlock(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(269, 269, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (2): InstanceNorm2d(269, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (5): Conv2d(269, 269, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (6): InstanceNorm2d(269, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec2): Sequential(\n",
       "      (0): ReLUINSConvTranspose2d(\n",
       "        (model): Sequential(\n",
       "          (0): ConvTranspose2d(277, 138, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (1): LayerNorm()\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec3): Sequential(\n",
       "      (0): ReLUINSConvTranspose2d(\n",
       "        (model): Sequential(\n",
       "          (0): ConvTranspose2d(146, 73, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (1): LayerNorm()\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec4): Sequential(\n",
       "      (0): ConvTranspose2d(81, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (disContent): MD_Dis_content(\n",
       "    (model): Sequential(\n",
       "      (0): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(7, 7), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(7, 7), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "          (1): Conv2d(256, 256, kernel_size=(7, 7), stride=(2, 2))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): LeakyReLUConv2d(\n",
       "        (model): Sequential(\n",
       "          (0): ReflectionPad2d((0, 0, 0, 0))\n",
       "          (1): Conv2d(256, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (cls_loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from options import TestOptions\n",
    "from datasets import dataset_single\n",
    "from model import MD_multi\n",
    "from saver import save_imgs, save_concat_imgs\n",
    "\n",
    "# model\n",
    "print('\\n--- load model ---')\n",
    "model = MD_multi(opts)\n",
    "model.resume(opts.resume, train=False)\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "general_transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "class PandasDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,root_dir,transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "        image_names = glob.glob(os.path.join(root_dir,'image*.jpg'))\n",
    "        self.name_frame = [image_name.split('/')[-1] for image_name in image_names]\n",
    "        self.root_dir = root_dir\n",
    "        if transform:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.name_frame[idx]\n",
    "        image = Image.open(os.path.join(self.root_dir,img_name)).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "    \n",
    "def load_image(path):\n",
    "    im_file = Image.open(path)\n",
    "    im_file_arr = np.asarray(im_file)[:,:,:3]\n",
    "    im_file = Image.fromarray(im_file_arr)\n",
    "    im_file = general_transforms(im_file)\n",
    "    \n",
    "\n",
    "    return im_file\n",
    "\n",
    "def analyze_folder(folder):\n",
    "    columns = ['name']\n",
    "    feature_dframe = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # first iterate over all names\n",
    "    file_list = os.listdir(folder)\n",
    "    \n",
    "    for im_path in file_list:\n",
    "        if not ('.jpg' in im_path):\n",
    "            continue\n",
    "        if 'mask' in im_path:\n",
    "            continue\n",
    "        \n",
    "        new_row_append = {'name':im_path}\n",
    "        feature_dframe=feature_dframe.append(new_row_append, ignore_index=True)\n",
    "        \n",
    "    # then load all images and extract features\n",
    "    feature_arr = np.zeros((len(feature_dframe), 256))\n",
    "    filled_in = 0\n",
    "    for im_path in file_list:\n",
    "        if not ('.jpg' in im_path):\n",
    "            continue\n",
    "        if 'mask' in im_path:\n",
    "            continue\n",
    "        image = load_image(os.path.join(folder, im_path))\n",
    "        features = content_code(image.unsqueeze(0))\n",
    "        feature_arr[filled_in, :] = features.numpy()\n",
    "\n",
    "        filled_in += 1\n",
    "    return feature_dframe, feature_arr\n",
    "\n",
    "def analyze_folder_batchwise(folder,batch_size=16):\n",
    "    columns = ['name']\n",
    "    feature_dframe = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # first iterate over all names\n",
    "    train_dataset =  PandasDataset(folder,transform = general_transforms)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = batch_size, shuffle=False,\n",
    "        num_workers=4, pin_memory=True)\n",
    "    \n",
    "    feature_dframe['name']=train_dataset.name_frame\n",
    "        \n",
    "    # then load all images and extract features\n",
    "    feature_arr = np.zeros((len(train_dataset), 256))\n",
    "    filled_in = 0\n",
    "    for i, images in enumerate(train_loader):\n",
    "        features = model.enc_c.forward(images.cuda())\n",
    "        if filled_in<len(train_dataset)-batch_size:\n",
    "            feature_arr[filled_in:filled_in+batch_size, :] = features.reshape((batch_size,-1,128*128)).mean(dim=2).cpu().numpy()\n",
    "            filled_in += batch_size\n",
    "        else:\n",
    "            feature_arr[filled_in:, :] = features.reshape((features.size()[0],-1,128*128)).mean(dim=2).cpu().numpy()\n",
    "    return feature_dframe, feature_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- patient: f41758ea4ca2fa1520cfe98a4c064e54 with 216 images in 5.393353700637817s\n"
     ]
    }
   ],
   "source": [
    "# launch feature extraction and save it\n",
    "super_directory = '/storage/groups/qscd01/datasets/panda_2/sample_data'\n",
    "super_directory_save = '/storage/groups/qscd01/datasets/panda_2/mdmm_feature'\n",
    "\n",
    "for patient in os.listdir(os.path.join(super_directory))[0:1]:\n",
    "    time_before = time.time()\n",
    "    \n",
    "    feature_dframe, feature_arr = analyze_folder_batchwise(os.path.join(super_directory, patient))\n",
    "    save_dir = os.path.join(super_directory_save, patient)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(os.path.join(save_dir))\n",
    "    feature_dframe.to_csv(os.path.join(save_dir, \"file_order.csv\"), index=False)\n",
    "    np.save(os.path.join(save_dir, \"features.npy\"), feature_arr)\n",
    "    \n",
    "    time_after = time.time()\n",
    "    print(\"---- patient: \" + patient + \" with \" + str(len(feature_dframe)) + \" images in \" + str(time_after-time_before) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
